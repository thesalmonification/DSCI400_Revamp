{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thesalmonification/DSCI400_Revamp/blob/master/MLP_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YryecdzXOcb9",
        "colab_type": "text"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3UuXNWeEp65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "melVyoNYOfnF",
        "colab_type": "text"
      },
      "source": [
        "Add Google Shared Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxpL8wdTEwKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Written in Google Collab: add drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx6f-9ADO2m6",
        "colab_type": "text"
      },
      "source": [
        "Load Pos/Neg Emotion Sessions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btVSQUl5E3iW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the pos/emo sessions\n",
        "#Purposefully limit the pos emotions to the first 200; this equalizes the pos/neg amounts\n",
        "PosEmoSessions = list(pd.read_csv('/content/drive/Shared drives/DSCI400_Revamp/PosEmoSessions.csv',header=None)[0])[:200]\n",
        "NegEmoSessions = list(pd.read_csv('/content/drive/Shared drives/DSCI400_Revamp/NegEmoSessions.csv',header=None)[0])\n",
        "\n",
        "#Concatenate all pos/neg emo sessions\n",
        "all_sessions = PosEmoSessions + NegEmoSessions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jf8behCO5-H",
        "colab_type": "text"
      },
      "source": [
        "Centering Helper Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIRmOHqyLwgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Helper function for centering a data matrix\n",
        "def center_matrix(pandas_matrix):\n",
        "  data_array = pandas_matrix.T.to_numpy()\n",
        "\n",
        "  mean_array = np.mean(data_array,axis=1)\n",
        "  mean_array = np.reshape(mean_array,(-1,1))\n",
        "  mean_array = np.repeat(mean_array,6080,axis=1)\n",
        "\n",
        "\n",
        "  data_array = data_array - mean_array\n",
        "\n",
        "  return data_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi8LvwXnO8qr",
        "colab_type": "text"
      },
      "source": [
        "Process Waveforms using Centering and FFT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7GOVMJkE9wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#List of channels and conversion dictionary (pos = 0, neg = 1)\n",
        "chs = ['Fp1','Fp2','AF3','AF4','F7','F3','Fz','F4','F8','FC5','FC1','FC2','FC6','T7','C3','Cz','C4','T8','CP5','CP1','CP2','CP6','P7','P3','Pz','P4','P8','PO3','PO4','O1','Oz','O2']\n",
        "to_binary_dict = {'0':0,'4':0,'6':0,'11':0,'1':1,'2':1,'3':1,'5':1,'12':1}\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#Iterate over the first session\n",
        "\n",
        "#Center Data and FFT it\n",
        "data_pd = pd.read_hdf('/content/drive/Shared drives/DSCI400_Revamp/Waveform_Vocoded_Equalized_Downsampled_Data.h5',key=all_sessions[0])\n",
        "data_array = center_matrix(data_pd)\n",
        "data_array = np.fft.fft(data_array)\n",
        "\n",
        "#Treat electrodes separately; add 32 label values \n",
        "label_data = pd.read_hdf('/content/drive/Shared drives/DSCI400_Revamp/Label_Data.h5',key=all_sessions[0]+'_labels').T\n",
        "label_list = [to_binary_dict[label_data['feltEmo'].to_numpy()[0]]] * 32\n",
        "###############################################################################\n",
        "#Iterate over the other sessions\n",
        "\n",
        "for session in all_sessions[1:]:\n",
        "  #Center and FFT\n",
        "  data_pd = pd.read_hdf('/content/drive/Shared drives/DSCI400_Revamp/Waveform_Vocoded_Equalized_Downsampled_Data.h5',key=session)\n",
        "  session_array = center_matrix(data_pd)\n",
        "  session_array = np.fft.fft(session_array)\n",
        "  data_array = np.vstack((data_array,session_array))\n",
        "\n",
        "  #Add label values\n",
        "  label_data = pd.read_hdf('/content/drive/Shared drives/DSCI400_Revamp/Label_Data.h5',key=session+'_labels').T\n",
        "  label_list = label_list + [to_binary_dict[label_data['feltEmo'].to_numpy()[0]]] * 32\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkX3ZS8vPyYs",
        "colab_type": "text"
      },
      "source": [
        "Truncate FFT Coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms9W1VmWFSJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Truncate to first 50 coefficients (approx 0-3 Hz)\n",
        "data_array = data_array[:,:50]\n",
        "\n",
        "#Display some random FFT magnitudes to verify\n",
        "for i in range(467,478):\n",
        "  plt.plot(abs(data_array[i,:]))\n",
        "\n",
        "plt.title('FFT Magnitude')\n",
        "plt.xlabel('FFT Coefficient')\n",
        "plt.ylabel('Magnitude')\n",
        "plt.show() #Shows successfully truncated waveforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dptIm0lyQJX2",
        "colab_type": "text"
      },
      "source": [
        "Define Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wML0cbUtN40m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make a Keras Model\n",
        "def KerasModel(lr):\n",
        "  \"\"\"\n",
        "  Creates a Keras MLP model for FFT input.\n",
        "  \"\"\"\n",
        "  #Paste the Keras Sequential model code here...\n",
        "  #Ensure that you have a learning rate varible \"lr\" in the optimizer declaration\n",
        "\n",
        "  model = tf.keras.Sequential(name='MLP')\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(320,input_shape=(50,),activation='relu',name='50_Nodes'))\n",
        "\n",
        "  model.add(tf.keras.layers.Dropout(0.6))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(80,activation='relu',name='80_Nodes')) #80\n",
        "\n",
        "  model.add(tf.keras.layers.Dropout(0.5,name='0.5_Dropout'))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(30,name='30_Nodes')) #30\n",
        "\n",
        "  model.add(tf.keras.layers.Dropout(0.6,name='0.6_Dropout2'))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(1, activation='sigmoid',name='1_Node'))\n",
        "\n",
        "  #YOUR OPTIMIZER MUST CONTAIN A LEARNING RATE!\n",
        "  sgd = tf.keras.optimizers.Adam(lr = lr, decay = 1e-5)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adTIg5B6QQnv",
        "colab_type": "text"
      },
      "source": [
        "Make Test Train Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYDNBgsgPB_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_array, label_list, test_size=0.33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSlcP0b4Qf0u",
        "colab_type": "text"
      },
      "source": [
        "Train and Validate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNkw663grkYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Generates a FFT input MLP and creates train vs validation graphs for loss \n",
        "## and accuracy over 100 epochs\n",
        "lr = 0.001\n",
        "#Make Model\n",
        "model2 = KerasModel(lr)\n",
        "model2.summary()\n",
        "\n",
        "#Train Model\n",
        "history = model2.fit(X_train, np.array(y_train), epochs=100, batch_size=32, validation_data = (X_test, np.array(y_test)), verbose=1)\n",
        "test_loss2, test_acc2 = model2.evaluate(X_test,np.array(y_test))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12,10))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Time Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Time Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower left')\n",
        "\n",
        "#Save figure and plot\n",
        "#plt.savefig('/content/drive/Shared drives/DSCI400_Revamp/Code/Modeling/MLP_TrainVal_Curves.png')\n",
        "plt.show()\n",
        "\n",
        "#Destroy the old model to prevent overloading GPU\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROTbRNQLQ7r-",
        "colab_type": "text"
      },
      "source": [
        "Plot ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNjhdM-Rrssc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Trains a model using the epochs determined from the two cells above and \n",
        "## generates an ROC curve\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "# Model training\n",
        "model_auc = KerasModel(lr)\n",
        "model_auc.fit(X_train, np.array(y_train), epochs=25, batch_size=32, validation_data = (X_test, np.array(y_test)), verbose=1)\n",
        "\n",
        "# ROC creation\n",
        "y_pred_auc = model_auc.predict(X_test).ravel()\n",
        "\n",
        "#print(sum(y_pred_auc > 0.5))\n",
        "\n",
        "fpr_auc, tpr_auc, threshold_auc = roc_curve(np.array(y_test), y_pred_auc)\n",
        "auc_forimg = auc(fpr_auc, tpr_auc)\n",
        "\n",
        "plt.plot(fpr_auc, tpr_auc, label = 'Model AUC = {:.3f}'.format(auc_forimg))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='best')\n",
        "#plt.savefig('/content/drive/Shared drives/DSCI400_Revamp/Code/Modeling/MLP_ROC.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zz0776KRSx-",
        "colab_type": "text"
      },
      "source": [
        "Perform and Plot 10-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laku_LPsPIfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Perform n-fold cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "label_array = np.array(label_list)\n",
        "fold_accuracies = []\n",
        "n_split=10\n",
        " \n",
        "#For each fold, generate model and test it\n",
        "for train_index,test_index in KFold(n_split,shuffle=True).split(data_array):\n",
        "  x_train,x_test=data_array[train_index],data_array[test_index]\n",
        "  y_train,y_test=label_array[train_index],label_array[test_index]\n",
        "\n",
        "\n",
        "  model = KerasModel(0.001)\n",
        "\n",
        "  history = model.fit(x_train,y_train,epochs=25,batch_size=BATCH_SIZE, verbose=1)\n",
        "  test_loss, test_acc = model.evaluate(x_test,y_test)\n",
        "  fold_accuracies.append(test_acc)\n",
        "\n",
        "  #Destroy the old model to prevent overloading GPU\n",
        "  tf.keras.backend.clear_session()\n",
        "  \n",
        "  #Print the number of 0's/1's produced to verify actual classification\n",
        "  print(\"The Number of 1's is:\" + str(np.count_nonzero(model.predict_classes(X_test))))\n",
        "  print(\"The Number of 0's is:\" + str(np.count_nonzero(model.predict_classes(X_test) ==0 )))\n",
        "  print('-------------------------------------------')\n",
        "\n",
        "#Display histogram of 10-fold values\n",
        "plt.hist(np.array(fold_accuracies) * 100)\n",
        "plt.title('N-fold Cross Validation: ' + str(int(np.mean(fold_accuracies) * 100)) + '% Avg. Accuracy')\n",
        "plt.xlabel('Accuracy (%)')\n",
        "plt.ylabel('Number of Folds')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVBzLOULQd14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}