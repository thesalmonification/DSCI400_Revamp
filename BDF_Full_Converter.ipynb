{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "BDF_Full_Converter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thesalmonification/DSCI400_Revamp/blob/master/BDF_Full_Converter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19Mh2KEp1-7b",
        "colab_type": "text"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVin52UR9gs2",
        "colab_type": "code",
        "outputId": "aa722dfd-4415-442d-e3fc-f0ff7a270a9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import mne"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/7c/ad1b52a3fdd4be8f55e183f1eff7d76f48cd1bee83c5630f9c26770e032e/mne-0.19.2-py3-none-any.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.4.1)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.19.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89uEkdNQ2CIZ",
        "colab_type": "text"
      },
      "source": [
        "Connect to Shared Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S26xzWi79gs9",
        "colab_type": "code",
        "outputId": "00d1903e-357c-49c6-dc5e-0e8b1406135d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#This file was written on collab, so must import shared drives...\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Outdated from when run on local machine...\n",
        "\n",
        "#os.chdir('/media/duncan/DATA/hci_db_raw/Sessions')\n",
        "#subfolders = os.listdir()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXeMXKm72IdI",
        "colab_type": "text"
      },
      "source": [
        "List all sessions to parse over"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRjcFSr3nSUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Enter the sessions directory, this contains all raw BDF files of the experiment...\n",
        "subfolders = os.listdir('/content/drive/Shared drives/DSCI400/Sessions')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnApeokW2fF4",
        "colab_type": "text"
      },
      "source": [
        "Parse the EEG waveforms and save to hdf5 files..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wnBtJqJ9gtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#List of EEG channels used in this study\n",
        "#['Fp1', 'AF3', 'F3', 'F7', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'P3', 'P7', 'PO3', 'O1', 'Oz', 'Pz', 'Fp2', 'AF4', 'Fz', 'F4', 'F8', 'FC6', 'FC2', 'Cz', 'C4', 'T8', 'CP6', 'CP2', 'P4', 'P8', 'PO4', 'O2']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for subfolder in subfolders:\n",
        "    print(subfolder)\n",
        "    os.chdir('/content/drive/Shared drives/DSCI400/Sessions/' + subfolder)\n",
        "    #bdf_files = glob.glob('/content/drive/Shared drives/DSCI400/Sessions/' + subfolder + '/*.bdf')\n",
        "    #xml_files = glob.glob('/content/drive/Shared drives/DSCI400/Sessions/session.xml')\n",
        "    bdf_files = glob.glob('*.bdf')\n",
        "    xml_files = glob.glob('session.xml')\n",
        "    if (len(bdf_files) == 0) or (len(xml_files) == 0):\n",
        "        os.chdir('..')\n",
        "        continue #case where no .bdf/.xml file saved so useless to keep\n",
        "    \n",
        "    \n",
        "    #Parse the .xml file and get the emotional attributes\n",
        "    #Save the file as a .csv\n",
        "    root = ET.parse('session.xml').getroot()\n",
        "    root_dict = root.attrib\n",
        "    emotion_dict = {k:root_dict[k] for k in ('feltEmo','feltArsl','feltVlnc','feltCtrl','feltPred','mediaFile') if k in root_dict}\n",
        "    df = pd.DataFrame.from_dict(emotion_dict,orient='index',columns=['Value'])\n",
        "    df.index.name = 'Label'\n",
        "    \n",
        "    print(df)\n",
        "\n",
        "    #df.to_csv('/media/duncan/DATA/hci_db_raw/Label_CSV/'+subfolder+'_labels.csv') #outdated, will no longer use csv\n",
        "    df.to_hdf('/content/drive/Shared drives/DSCI400/Label_Data.h5',key='t' + subfolder+'_labels',complevel=4,format='table')\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    #In the other case, I have a single .bdf/.xml file pair to parse \n",
        "    #I want to build .csv files to replace the .bdf files for every trial\n",
        "    #Open the raw data\n",
        "    raw = mne.io.read_raw_bdf(bdf_files[0], preload=True)\n",
        "    chs = raw.info['ch_names'][:32]\n",
        "    \n",
        "    #parse over every EEG channel and save to an array\n",
        "    #Start a data array by grabbing first channel\n",
        "    \n",
        "    #Older style (no trimming)\n",
        "    #data_array = raw[chs[0]][0]\n",
        "    \n",
        "    #Added 2/18 to trim portions where EEG is \"shut off\"\n",
        "    ####################################\n",
        "    ch0 = raw[chs[0]][0][0]\n",
        "    \n",
        "    ch0[abs(ch0)<3e-8] = 0\n",
        "    ch0 = np.trim_zeros(ch0)\n",
        "    \n",
        "    ch0 = ch0.reshape(-1,1).T\n",
        "    \n",
        "    data_array = ch0\n",
        "    ####################################\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    for ch in chs[1:]:   \n",
        "        \n",
        "        #Uncomment if you want to see before/after for trimming\n",
        "        #plt.figure()\n",
        "        #plt.plot(raw[ch][0][0])\n",
        "        \n",
        "        \n",
        "        #Older style (no trimming)\n",
        "        #data = raw[ch][0] #the 1st index is just idx samples counting up (ie not needed)\n",
        "        \n",
        "        #Added 2/18 to trim portions where EEG is \"shut off\"\n",
        "        #####################################\n",
        "        data = raw[ch][0][0]\n",
        "        \n",
        "        data[abs(data)<3e-8] = 0\n",
        "        data = np.trim_zeros(data)\n",
        "        \n",
        "        data = data.reshape(-1,1).T\n",
        "        \n",
        "        \n",
        "        #Uncomment if you want to see before/after for trimming\n",
        "        #plt.figure()\n",
        "        #plt.plot(data[0])\n",
        "        \n",
        "        \n",
        "        \n",
        "        ####################################\n",
        "        data_array = np.concatenate((data_array,data),axis=0)\n",
        "        \n",
        "\n",
        "    \n",
        "    num_samples = max(data_array.shape)\n",
        "\n",
        "    #Save the file to CSV using Pandas\n",
        "    df = pd.DataFrame(data_array,index=chs,columns=range(0,num_samples)).T\n",
        "    \n",
        "    print(df.head())\n",
        "\n",
        "    #df.to_csv('/media/duncan/DATA/hci_db_raw/Waveform_Trimmed_CSV/'+subfolder + '.csv',index=chs,columns=range(0,num_samples)) #Outdated no longer using CSV\n",
        "    df.to_hdf('/content/drive/Shared drives/DSCI400/Waveform_Data.h5',key='t' + subfolder ,complevel=4,format='table')\n",
        "    print('-----------------------------------')\n",
        "    os.chdir('..')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LRtZkh72mVU",
        "colab_type": "text"
      },
      "source": [
        "Build Keys files to make parsing of the HDF5 files easier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMsN86Wo9gtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save files called Waveform_Data_Keys.h5 and Label_Data_Keys.h5, to be able to parse Waveform_Data and Label_Data with ease later.\n",
        "\n",
        "waveform_keys = []\n",
        "label_keys = []\n",
        "\n",
        "for folder in susbfolders:\n",
        "  waveform_keys.append('t' + folder)\n",
        "  label_keys.append('t' + folder + '_labels')\n",
        "\n",
        "\n",
        "waveform_df = df.DataFrame(waveform_keys)\n",
        "label_df = df.DataFrame(label_keys)\n",
        "\n",
        "waveform_df.to_csv('/content/drive/Shared drives/DSCI400/Waveform_Data_Keys.csv')\n",
        "label_df.to_csv('/content/drive/Shared drives/DSCI400/Label_Data_Keys.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}